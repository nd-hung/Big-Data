{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "covered-respect",
   "metadata": {},
   "source": [
    "# Xử lý dữ liệu văn bản với PySpark\n",
    "\n",
    "\n",
    "- [Khởi tạo ứng dụng PySpark](#sparkcontext)\n",
    "- [Tạo RDD](#create_rdd)\n",
    "- [Các xử lý trên RDD](#rdd_progamming)\n",
    "- [Lưu kết quả lên bộ nhớ ngoài](#save_results)\n",
    "\n",
    "- [Bài tập](#excercises)\n",
    "\n",
    "- [Tham khảo](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-surgeon",
   "metadata": {},
   "source": [
    "## Khởi tạo ứng dụng PySpark <a name=\"sparkcontext\"/>\n",
    "\n",
    "Mỗi ứng dụng Spark được quản lý bởi một trình điều khiển (driver). Trình điều khiển chứa hàm main() của trình ứng dụng, tạo dữ liệu phân tán trên cụm máy tính rồi thực hiện các xử lý trên chúng. Trình điều khiển kết nối với Spark thông qua một đối tượng của lớp SparkContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dutch-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo thư viện\n",
    "import os, shutil\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# tạo đối tượng Spark context \n",
    "sc = SparkContext(\"local\", \"Text processing with PySpark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-writer",
   "metadata": {},
   "source": [
    "## Tạo RDD\n",
    "\n",
    "Spark thực hiện các xử lý trên một cấu trúc gọi là resilient distributed datasets (RDDs). Mỗi RDD được chia thành các phân vùng (partitions), mỗi phân vùng có thể được xử lý trên các trạm khác nhau trên cụm máy tính. RDD có thể chứa kiểu dữ liệu của Python, Java, Scala, hoặc đối tượng của lớp tự định nghĩa. Các xử lý của Spark đều xoay quanh RDD: tạo mới, biến đổi RDD, tính toán kết quả từ RDD.\n",
    "\n",
    "Sau khi tạo đối tượng điều khiển SparkContext, cần tạo RDD để tiến hành các xử lý. Một cách thông dụng là tạo RDD từ tập dữ liệu sẵn có trên bộ nhớ ngoài. Ví dụ, lệnh sau đây tạo RDD từ dữ liệu văn bản trên bộ nhớ ngoài:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "celtic-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"/home/hung/Downloads/gutenberg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-forest",
   "metadata": {},
   "source": [
    "Nếu thực hiện thành công, biến `lines` là một đối tượng RDD chứa tất cả các dòng văn bản của tập dữ liệu.\n",
    "Để tách mỗi dòng thành các từ riêng biệt, cần gọi phương thức biến đổi (transformation) có tên là flatMap(). Phương thức flatMap() gọi hàm do người dùng định nghĩa lên các phần tử của RDD và trả về một RDD chứa các phần tử kết quả của lời gọi hàm.\n",
    "Ví dụ: để tách mỗi dòng văn bản thành các từ riêng biệt, có thể định nghĩa hàm Python như sau:\n",
    "```python\n",
    "lambda line: line.split(\" \")\n",
    "```\n",
    "*hàm không có tên* này nhận dữ liệu vào là một dòng văn bản, trả về một danh sách các từ của dòng đó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "separated-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the lines into separated words\n",
    "words = lines.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-thumbnail",
   "metadata": {},
   "source": [
    "## Xử lý trên RDD <a name=\"rdd_progamming\"/>\n",
    "\n",
    "Các xử lý trên RDDs được chia làm hai loại: *biến đổi* (transformations) và *hành động* (actions).\n",
    "Thao tác biến đổi thực hiện xử lý trên RDDs và *trả về một RDD mới*, chẳng hạn như map(), filter(). Thao tác hành động xử lý RDD và *trả về kết quả cho trình điều khiển hoặc lưu lên bộ nhớ ngoài*, chẳng hạn count() hay take().\n",
    "\n",
    "Ví dụ, để đếm tần số của mỗi từ trên tập dữ liệu, trước hết sử dụng phương thức map() để biến đổi mỗi từ thành một cặp <key, value> = <word, 1>. Sau đó gọi phương thức reduceByKey() để thực hiện gộp kết quả theo qui tắc được định nghĩa trong hàm truyền cho nó. Ở đây hàm\n",
    "```python\n",
    "lambda a, b: a + b\n",
    "```\n",
    "nhận vào hai đối số và trả về tổng của chúng. Trong trường hợp này, phương thức reduceByKey() sẽ gộp theo từ và trả về tổng số đếm của mỗi cặp <word, 1>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "canadian-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the occurrence of each word\n",
    "wordFrequencies = words.map(lambda word: (word, 1)).reduceByKey(lambda a,b: a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-stone",
   "metadata": {},
   "source": [
    "Trong trường hợp muốn đếm tổng số từ trong tập dữ liệu, có thể thực hiện như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "resistant-gossip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of lines: 78753\n",
      "\n",
      "Total number of words: 664661\n",
      "\n",
      "Some results:\n",
      "[('Project', 185), ('of', 23948), ('Science,', 5), ('Vol.', 65), ('(of', 7), ('4),', 3), ('', 34586), ('for', 3372), ('the', 42097), ('anywhere', 18)]\n",
      "\n",
      "Top frequent words:\n",
      "[('the', 42097), ('', 34586), ('of', 23948), ('and', 16916), ('a', 12058), ('to', 12034), ('in', 11885), ('is', 7408), ('that', 6109), ('it', 4979)]\n"
     ]
    }
   ],
   "source": [
    "# count total number of words in the dataset\n",
    "totalWordNumber = words.map(lambda word: 1).reduce(lambda a,b: a + b)\n",
    "\n",
    "# display results\n",
    "# print the number of lines\n",
    "print('\\nTotal number of lines:', lines.count())\n",
    "\n",
    "# print total number of words in the dataset\n",
    "print('\\nTotal number of words:', totalWordNumber)\n",
    "\n",
    "# lấy ra 10 từ\n",
    "someResults = wordFrequencies.take(10)\n",
    "print(\"\\nSome results:\")\n",
    "print(someResults)\n",
    "\n",
    "# In ra top 10 từ xuất hiện nhiều nhất: \n",
    "topFrequentWords = wordFrequencies.takeOrdered(10, key = lambda x: -x[1])\n",
    "print(\"\\nTop frequent words:\")\n",
    "print(topFrequentWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-stretch",
   "metadata": {},
   "source": [
    "## Lưu kết quả lên bộ nhớ ngoài <a name=\"save_results\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "given-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the set of <word, frequency> to disk\n",
    "savingPath = \"/home/hung/labs/data/output/gutenberg-result\"\n",
    "\n",
    "if os.path.isdir(savingPath):\n",
    "    shutil.rmtree(savingPath, ignore_errors=True)\n",
    "\n",
    "wordFrequencies.saveAsTextFile(savingPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-observer",
   "metadata": {},
   "source": [
    "## Bài tập<a name=\"excercises\"/>\n",
    "\n",
    "1. Từ file `apache_logs` hãy lọc ra các dòng thông báo lỗi (chứa từ \"error\") với PySpark.\n",
    "2. Xử lý dữ liệu Twitter\n",
    "Cho file văn bản `elonmusk_tweets.csv` chứa các dòng tweets của Elon Musk từ 2011-2017. Dữ liệu được chia sẻ bởi [Adam Helsinger](https://data.world/adamhelsinger/elon-musk-tweets-until-4-6-17). Từ file dữ liệu trên, hãy thực hiện các xử lý sau với PySpark:\n",
    "- Liệt kê top 20 từ được nhắc đến nhiều nhất.\n",
    "- Liệt kê top 10 tài khoản được nhắc đến nhiều nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-prince",
   "metadata": {},
   "source": [
    "## Tham khảo <a name=\"references\"/>\n",
    "[PySpark Documentation\n",
    "](https://spark.apache.org/docs/3.1.1/api/python/)\n",
    "\n",
    "\n",
    "Zaharia M., et al. Learning Spark (O'Reilly, 2015)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
